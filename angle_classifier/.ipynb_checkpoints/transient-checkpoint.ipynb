{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all image paths within a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_paths = glob.glob(\"./data/data_set/box_pictures/training/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted(list(\n",
    "    map(lambda path: sorted(glob.glob(f\"{path}/*\")),\n",
    "        training_paths)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['./data/data_set/box_pictures/training/box1_color/box1_1.png',\n",
       "  './data/data_set/box_pictures/training/box1_color/box1_2.png',\n",
       "  './data/data_set/box_pictures/training/box1_color/box1_3.png',\n",
       "  './data/data_set/box_pictures/training/box1_color/box1_4.png',\n",
       "  './data/data_set/box_pictures/training/box1_color/box1_5.png',\n",
       "  './data/data_set/box_pictures/training/box1_color/box1_6.png',\n",
       "  './data/data_set/box_pictures/training/box1_color/box1_7.png'],\n",
       " ['./data/data_set/box_pictures/training/box2_color/box2_1.png',\n",
       "  './data/data_set/box_pictures/training/box2_color/box2_2.png',\n",
       "  './data/data_set/box_pictures/training/box2_color/box2_3.png',\n",
       "  './data/data_set/box_pictures/training/box2_color/box2_4.png',\n",
       "  './data/data_set/box_pictures/training/box2_color/box2_5.png',\n",
       "  './data/data_set/box_pictures/training/box2_color/box2_6.png',\n",
       "  './data/data_set/box_pictures/training/box2_color/box2_7.png'],\n",
       " ['./data/data_set/box_pictures/training/box3_color/box3_1.png',\n",
       "  './data/data_set/box_pictures/training/box3_color/box3_2.png',\n",
       "  './data/data_set/box_pictures/training/box3_color/box3_3.png',\n",
       "  './data/data_set/box_pictures/training/box3_color/box3_4.png',\n",
       "  './data/data_set/box_pictures/training/box3_color/box3_5.png',\n",
       "  './data/data_set/box_pictures/training/box3_color/box3_6.png',\n",
       "  './data/data_set/box_pictures/training/box3_color/box3_7.png'],\n",
       " ['./data/data_set/box_pictures/training/box4_color/box4_1.png',\n",
       "  './data/data_set/box_pictures/training/box4_color/box4_2.png',\n",
       "  './data/data_set/box_pictures/training/box4_color/box4_3.png',\n",
       "  './data/data_set/box_pictures/training/box4_color/box4_4.png',\n",
       "  './data/data_set/box_pictures/training/box4_color/box4_5.png',\n",
       "  './data/data_set/box_pictures/training/box4_color/box4_6.png',\n",
       "  './data/data_set/box_pictures/training/box4_color/box4_7.png'],\n",
       " ['./data/data_set/box_pictures/training/box5_color/box5_1.png',\n",
       "  './data/data_set/box_pictures/training/box5_color/box5_2.png',\n",
       "  './data/data_set/box_pictures/training/box5_color/box5_3.png',\n",
       "  './data/data_set/box_pictures/training/box5_color/box5_4.png',\n",
       "  './data/data_set/box_pictures/training/box5_color/box5_5.png',\n",
       "  './data/data_set/box_pictures/training/box5_color/box5_6.png',\n",
       "  './data/data_set/box_pictures/training/box5_color/box5_7.png'],\n",
       " ['./data/data_set/box_pictures/training/box6_color/box6_1.png',\n",
       "  './data/data_set/box_pictures/training/box6_color/box6_2.png',\n",
       "  './data/data_set/box_pictures/training/box6_color/box6_3.png',\n",
       "  './data/data_set/box_pictures/training/box6_color/box6_4.png',\n",
       "  './data/data_set/box_pictures/training/box6_color/box6_5.png',\n",
       "  './data/data_set/box_pictures/training/box6_color/box6_6.png',\n",
       "  './data/data_set/box_pictures/training/box6_color/box6_7.png'],\n",
       " ['./data/data_set/box_pictures/training/box7_color/box7_1.png',\n",
       "  './data/data_set/box_pictures/training/box7_color/box7_2.png',\n",
       "  './data/data_set/box_pictures/training/box7_color/box7_3.png',\n",
       "  './data/data_set/box_pictures/training/box7_color/box7_4.png',\n",
       "  './data/data_set/box_pictures/training/box7_color/box7_5.png',\n",
       "  './data/data_set/box_pictures/training/box7_color/box7_6.png',\n",
       "  './data/data_set/box_pictures/training/box7_color/box7_7.png']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the JSON and create the image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = open(\"data/data_set/data_set.json\", \"r\").read()\n",
    "data = json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'box': 1,\n",
       " 'brand': 'Liga',\n",
       " 'side_a': 21.5,\n",
       " 'side_b': 9.5,\n",
       " 'side_c': 4.7,\n",
       " 'main_colours': ['green', 'purple', 'red', 'white'],\n",
       " 'images': [{'name': 'box1_1', 'angle': 0},\n",
       "  {'name': 'box1_2', 'angle': 30},\n",
       "  {'name': 'box1_3', 'angle': 60},\n",
       "  {'name': 'box1_4', 'angle': 90},\n",
       "  {'name': 'box1_5', 'angle': 120},\n",
       "  {'name': 'box1_6', 'angle': 150},\n",
       "  {'name': 'box1_7', 'angle': 180}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_to_filenames(entry):\n",
    "    return list(\n",
    "    map(lambda image: f\"./data/data_set/box_pictures/training/box{entry['box']}_color/{image['name']}.png\",\n",
    "        entry[\"images\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = [entry_to_filenames(entry) for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/data_set/box_pictures/training/box1_color/box1_1.png',\n",
       " './data/data_set/box_pictures/training/box1_color/box1_2.png',\n",
       " './data/data_set/box_pictures/training/box1_color/box1_3.png',\n",
       " './data/data_set/box_pictures/training/box1_color/box1_4.png',\n",
       " './data/data_set/box_pictures/training/box1_color/box1_5.png',\n",
       " './data/data_set/box_pictures/training/box1_color/box1_6.png',\n",
       " './data/data_set/box_pictures/training/box1_color/box1_7.png']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the input and output for the cvm (support-vector-machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import skimage\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(image):\n",
    "    # Resize the image\n",
    "    image = image.resize((165, 165))\n",
    "    fd, _hog_image =  hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('data/data_set/data_set.json'))\n",
    "X = []\n",
    "Y = []\n",
    "for box in data:\n",
    "    for image_data in box[\"images\"]:\n",
    "        # Create the image path\n",
    "        image_path = f\"./data/data_set/box_pictures/training/box{box['box']}_color/{image_data['name']}.png\"\n",
    "        # Read in the image\n",
    "        image = Image.open(image_path)\n",
    "        # Append the processed image\n",
    "        X.append(preprocess_input(image))\n",
    "        # Append the angle\n",
    "        Y.append(image_data[\"angle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma=\"scale\", decision_function_shape='ovo')\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('data/data_set/test_set.json'))\n",
    "testX = []\n",
    "testY = []\n",
    "for box in data:\n",
    "    for image_data in box[\"images\"]:\n",
    "        # Create the image path\n",
    "        image_path = f\"./data/data_set/box_pictures/testing/test{box['box']}_color/{image_data['name']}.png\"\n",
    "        # Read in the image\n",
    "        image = Image.open(image_path)\n",
    "        # Append the processed image\n",
    "        testX.append(image)\n",
    "        # Append the angle\n",
    "        testY.append(image_data[\"angle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = list(\n",
    "    clf.predict([preprocess_input(image) for image in testX])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, (15, 30)),\n",
       " (1, (45, 60)),\n",
       " (2, (75, 90)),\n",
       " (3, (105, 90)),\n",
       " (4, (135, 150)),\n",
       " (5, (165, 0)),\n",
       " (6, (15, 30)),\n",
       " (7, (45, 60)),\n",
       " (8, (75, 120)),\n",
       " (9, (105, 120)),\n",
       " (10, (135, 120)),\n",
       " (11, (165, 150)),\n",
       " (12, (15, 120)),\n",
       " (13, (45, 120)),\n",
       " (14, (75, 120)),\n",
       " (15, (105, 120)),\n",
       " (16, (135, 120)),\n",
       " (17, (165, 120)),\n",
       " (18, (15, 30)),\n",
       " (19, (45, 60)),\n",
       " (20, (75, 60)),\n",
       " (21, (105, 120)),\n",
       " (22, (135, 120)),\n",
       " (23, (165, 150)),\n",
       " (24, (15, 90)),\n",
       " (25, (45, 120)),\n",
       " (26, (75, 90)),\n",
       " (27, (105, 120)),\n",
       " (28, (135, 120)),\n",
       " (29, (165, 90)),\n",
       " (30, (15, 30)),\n",
       " (31, (45, 60)),\n",
       " (32, (75, 60)),\n",
       " (33, (105, 120)),\n",
       " (34, (135, 120)),\n",
       " (35, (165, 150))]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(list(\n",
    "    zip(testY, classifications)\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications = list(\n",
    "    clf.predict([preprocess_input(image) for image in testX])\n",
    ")\n",
    "successful = 0\n",
    "for (tX, tY) in list(\n",
    "    zip(testY, classifications)\n",
    "):\n",
    "    if tX == tY or tX + 15 == tY or tX - 15 == tY:\n",
    "        successful += 1\n",
    "successful/len(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test clf_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = open(\"data/data_set_ext/training/config.json\", \"r\").read()\n",
    "data = json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': './img8_1.png', 'angle': 0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data[\"images\"]\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(image):\n",
    "    # Resize the image\n",
    "    image = image.resize((165, 165))\n",
    "    fd, _hog_image =  hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "    return fd\n",
    "\n",
    "path = \"./data/data_set_ext/training\"\n",
    "\n",
    "json_string = open(f\"{path}/config.json\", \"r\").read()\n",
    "data = json.loads(json_string)\n",
    "X_ext = []\n",
    "Y_ext = []\n",
    "for image_data in data:\n",
    "    # Create the image path\n",
    "    image_path = f\"{path}/{image_data['path']}\"\n",
    "    # Read in the image\n",
    "    image = Image.open(image_path)\n",
    "    # Append the processed image\n",
    "    X_ext.append(preprocess_input(image))\n",
    "    # Append the angle\n",
    "    Y_ext.append(image_data[\"angle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ext = svm.SVC(gamma=\"scale\", decision_function_shape='ovo')\n",
    "clf_ext.fit(X_ext, Y_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test clf_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/data_set_ext/testing\"\n",
    "\n",
    "json_string = open(f\"{path}/config.json\", \"r\").read()\n",
    "data = json.loads(json_string)\n",
    "test_X_ext = []\n",
    "test_Y_ext = []\n",
    "for image_data in data:\n",
    "    # Create the image path\n",
    "    image_path = f\"{path}/{image_data['path']}\"\n",
    "    # Read in the image\n",
    "    image = Image.open(image_path)\n",
    "    # Append the processed image\n",
    "    test_X_ext.append(preprocess_input(image))\n",
    "    # Append the angle\n",
    "    test_Y_ext.append(image_data[\"angle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = list(\n",
    "    clf_ext.predict(test_X_ext)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(120, 0),\n",
       " (30, 15),\n",
       " (90, 30),\n",
       " (90, 45),\n",
       " (90, 60),\n",
       " (120, 75),\n",
       " (120, 90),\n",
       " (120, 105),\n",
       " (120, 120),\n",
       " (120, 135),\n",
       " (120, 150),\n",
       " (120, 165),\n",
       " (120, 180),\n",
       " (0, 0),\n",
       " (30, 15),\n",
       " (30, 30),\n",
       " (90, 45),\n",
       " (60, 60),\n",
       " (60, 75),\n",
       " (90, 90),\n",
       " (90, 105),\n",
       " (120, 120),\n",
       " (120, 135),\n",
       " (120, 150),\n",
       " (150, 165),\n",
       " (0, 180),\n",
       " (180, 0),\n",
       " (0, 15),\n",
       " (30, 30),\n",
       " (90, 45),\n",
       " (60, 60),\n",
       " (60, 75),\n",
       " (90, 90),\n",
       " (105, 105),\n",
       " (120, 120),\n",
       " (135, 135),\n",
       " (150, 150),\n",
       " (180, 165),\n",
       " (180, 180),\n",
       " (120, 0),\n",
       " (45, 15),\n",
       " (30, 30),\n",
       " (45, 45),\n",
       " (45, 60),\n",
       " (60, 75),\n",
       " (105, 90),\n",
       " (120, 105),\n",
       " (120, 120),\n",
       " (135, 135),\n",
       " (120, 150),\n",
       " (135, 165),\n",
       " (120, 180)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(classifications, test_Y_ext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clf_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = open(\"data/data_set_alt/training/config.json\", \"r\").read()\n",
    "data = json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': './img1_1.png', 'angle': 0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(image):\n",
    "    # Resize the image\n",
    "    image = image.resize((165, 165))\n",
    "    fd, _hog_image =  hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "    return fd\n",
    "\n",
    "json_string1 = open(\"data/data_set_alt/training/config.json\", \"r\").read()\n",
    "data1 = json.loads(json_string1)\n",
    "X_alt = []\n",
    "Y_alt = []\n",
    "for image_data in data1:\n",
    "    # Create the image path\n",
    "    image_path = f\"./data/data_set_alt/training/{image_data['path']}\"\n",
    "    # Read in the image\n",
    "    image = Image.open(image_path)\n",
    "    # Append the processed image\n",
    "    X_alt.append(preprocess_input(image))\n",
    "    # Append the angle\n",
    "    Y_alt.append(image_data[\"angle\"])\n",
    "\n",
    "json_string2 = open(\"data/data_set_alt/testing/config.json\", \"r\").read()\n",
    "data2 = json.loads(json_string2)\n",
    "test_X_alt = []\n",
    "test_Y_alt = []\n",
    "for image_data in data2:\n",
    "    # Create the image path\n",
    "    image_path = f\"./data/data_set_alt/testing/{image_data['path']}\"\n",
    "    # Read in the image\n",
    "    image = Image.open(image_path)\n",
    "    # Append the processed image\n",
    "    test_X_alt.append(preprocess_input(image))\n",
    "    # Append the angle\n",
    "    test_Y_alt.append(image_data[\"angle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_alt = svm.SVC(gamma=\"scale\", decision_function_shape='ovo')\n",
    "clf_alt.fit(X_alt, Y_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = list(\n",
    "    clf_alt.predict([preprocess_input(image) for image_data in test_X_alt])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifications[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
